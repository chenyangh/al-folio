---
---

@article{acl2022,
  abbr={ACL},
  title={Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization},
  author={Liu, Puyuan and Huang, Chenyang and Mou, Lili},
  abstract={Text summarization aims to generate a short summary for an input text. In this work, we propose a Non-Autoregressive Unsupervised Summarization (NAUS) approach, which does not require parallel data for training. Our NAUS first performs edit-based search towards a heuristically defined score, and generates a summary as pseudo-groundtruth. Then, we train an encoder-only non-autoregressive Transformer based on the search result. We also proposed a dynamic programming approach for length-control decoding, which is important for the summarization task. Experiments on the Gigaword headline generation and DUC2004 datasets show that NAUS achieves state-of-the-art performance for unsupervised summarization, yet largely improving inference efficiency. Further, our algorithm is able to perform length-transfer summary generation.},
  year={2022},
  publisher=aps,
  pdf={https://openreview.net/forum?id=UNzc8gReN7m},
  selected={true},
  journal={ACL},
  code={https://github.com/MANGA-UOFA/NAUS}
}

@article{dslp,
  abbr={AAAI},
  title={Non-Autoregressive Translation with Layer-Wise Prediction and Deep Supervision},
  author={Huang, Chenyang and Zhou, Hao and Za{\"\i}ane, Osmar R and Mou, Lili and Li, Lei},
  abstract={How do we perform efficient inference while retaining high translation quality? Existing neural machine translation models, such as Transformer, achieve high performance, but they decode words one by one, which is inefficient. Recent non-autoregressive translation models speed up the inference, but their quality is still inferior. In this work, we propose DSLP, a highly efficient and high-performance model for machine translation. The key insight is to train a non-autoregressive Transformer with Deep Supervision and feed additional Layer-wise Predictions. We conducted extensive experiments on four translation tasks (both directions of WMT'14 EN-DE and WMT'16 EN-RO). Results show that our approach consistently improves the BLEU scores compared with respective base models. Specifically, our best variant outperforms the autoregressive model on three translation tasks, while being 14.8 times more efficient in inference.},
  year={2022},
  publisher=aps,
  pdf={https://arxiv.org/pdf/2110.07515.pdf},
  selected={true},
  journal={AAAI},
  code={https://github.com/chenyangh/DSLP}
}

@article{naacl,
  abbr={NAACL},
  title={Seq2Emo: A Sequence to Multi-Label Emotion Classification Model},
  author={Huang, Chenyang and Trabelsi, Amine and Qin, Xuebin and Farruque, Nawshad and Mou, Lili and Zaiane, Osmar R},
  abstract={Multi-label emotion classification is an important task in NLP and is essential to many applications. In this work, we propose a sequence-to-emotion (Seq2Emo) approach, which implicitly models emotion correlations in a bi-directional decoder. Experiments on SemEval’18 and GoEmotions datasets show that our approach outperforms state-of-the-art methods (without using external data). In particular, Seq2Emo outperforms the binary relevance (BR) and classifier chain (CC) approaches in a fair setting.},
  journal={NAACL},
  year={2021},
  publisher=aps,
  url={https://dl.acm.org/doi/abs/10.1145/3459637.3482182},
  pdf={https://aclanthology.org/2021.naacl-main.375},
  selected={true},
  code={https://github.com/chenyangh/Seq2Emo},
}

@article{cikm,
  abbr={CIKM},
  title={Simulated Annealing for Emotional Dialogue Systems
},
  author={Dong, Chengzhang and Huang, Chenyang and Za{\"\i}ane, Osmar and Mou, Lili},
  abstract={Explicitly modeling emotions in dialogue generation has important applications, such as building empathetic personal companions. In this study, we consider the task of expressing a specific emotion for dialogue generation. Previous approaches take the emotion as a training signal, which may be ignored during inference. Here, we propose a search-based emotional dialogue system by simulated annealing (SA). Specifically, we first define a scoring function that combines contextual coherence and emotional correctness. Then, SA iteratively edits a general response, and search for a generation with a high score. In this way, we enforce the presence of the desired emotion. We evaluate our system on the NLPCC2017 dataset. The proposed method shows about 12% improvements in emotion accuracy compared with the previous state-of-the-art method, without hurting the generation quality (measured by BLEU).},
  journal={CIKM},
  year={2021},
  publisher=aps,
  url={https://dl.acm.org/doi/abs/10.1145/3459637.3482182},
  pdf={https://arxiv.org/abs/2109.10715?context=cs},
  selected={true},
  code={https://github.com/Dio990521/SAEDS},
}

@article{tpami,
  abbr={ArXiv},
  title={Boundary-Aware Segmentation Network for Mobile and Web Applications},
  author={Qin, Xuebin and Fan, Deng-Ping and Huang, Chenyang and Diagne, Cyril and Zhang, Zichen and Sant'Anna, Adri{\`a} Cabeza and Suarez, Albert and Jagersand, Martin and Shao, Ling},
  abstract={Although deep models have greatly improved the accuracy and robustness of image segmentation, obtaining segmentation results with highly accurate boundaries and fine structures is still a challenging problem. In this paper, we propose a simple yet powerful Boundary-Aware Segmentation Network (BASNet), which comprises a predict-refine architecture and a hybrid loss, for highly accurate image segmentation. The predict-refine architecture consists of a densely supervised encoder-decoder network and a residual refinement module, which are respectively used to predict and refine a segmentation probability map. The hybrid loss is a combination of the binary cross entropy, structural similarity and intersection-over-union losses, which guide the network to learn three-level (ie, pixel-, patch- and map- level) hierarchy representations. We evaluate our BASNet on two reverse tasks including salient object segmentation, camouflaged object segmentation, showing that it achieves very competitive performance with sharp segmentation boundaries. Importantly, BASNet runs at over 70 fps on a single GPU which benefits many potential real applications. Based on BASNet, we further developed two (close to) commercial applications: AR COPY & PASTE, in which BASNet is integrated with augmented reality for "COPYING" and "PASTING" real-world objects, and OBJECT CUT, which is a web-based tool for automatic object background removal. Both applications have already drawn huge amount of attention and have important real-world impacts.},
  journal={Under review of TPAMI},
  year={2021},
  publisher=aps,
  pdf={https://arxiv.org/abs/2101.04704},
  code={https://github.com/xuebinqin/BASNet},
  selected={false}
}

@article{acl2021,
  abbr={ACL},
  title={Optimizing Deeper Transformers on Small Datasets},
  author={Xu, Peng and Kumar, Dhruv and Yang, Wei and Zi, Wenjie and Tang, Keyi and Huang, Chenyang and Cheung, Jackie Chi Kit and Prince, Simon JD and Cao, Yanshuai},
  abstract={It is a common belief that training deep transformers from scratch requires large datasets. Consequently, for small datasets, people usually use shallow and simple additional layers on top of pre-trained models during fine-tuning. This work shows that this does not always need to be the case: with proper initialization and optimization, the benefits of very deep transformers can carry over to challenging tasks with small datasets, including Text-to-SQL semantic parsing and logical reading comprehension. In particular, we successfully train  layers of transformers, comprising  fine-tuned layers from pre-trained RoBERTa and  relation-aware layers trained from scratch. With fewer training steps and no task-specific pre-training, we obtain the state-of-the-art performance on the challenging cross-domain Text-to-SQL parsing benchmark Spider. We achieve this by deriving a novel Data-dependent Transformer Fixed-update initialization scheme (DT-Fixup), inspired by the prior T-Fixup work. Further error analysis shows that increasing depth can help improve generalization on small datasets for hard cases that require reasoning and structural understanding.},
  journal={ACL},
  year={2021},
  publisher=aps,
  url={https://arxiv.org/abs/2012.153552},
  pdf={https://aclanthology.org/2021.acl-long.163},
  selected={true},
  code={https://github.com/BorealisAI/DT-Fixup},
}



@article{spnlp,
  abbr={SPNLP@ACL},
  title={A Globally Normalized Neural Model for Semantic Parsing},
  author={Huang, Chenyang  and  Yang, Wei  and  Cao, Yanshuai  and Za{\"\i}ane, Osmar  and  Mou, Lili},
  abstract={In this paper, we propose a globally normalized model for context-free grammar (CFG)-based semantic parsing. Instead of predicting a probability, our model predicts a real-valued score at each step and does not suffer from the label bias problem. Experiments show that our approach outperforms locally normalized models on small datasets, but it does not yield improvement on a large dataset.},
  journal={SPNLP@ACL},
  year={2021},
  publisher=aps,
  url={https://aclanthology.org/2021.spnlp-1.7},
  pdf={https://aclanthology.org/2021.spnlp-1.7.pdf},
  selected={true},
}

@article{union,
  abbr={SemEval},
  title={ANA at SemEval-2020 Task 4: mUlti-task learNIng for cOmmonsense reasoNing (UNION)},
  author={Konar, Anandh and Huang, Chenyang and Trabelsi, Amine and Zaiane, Osmar R},
  abstract={In this paper, we describe our mUlti-task learNIng for cOmmonsense reasoNing (UNION) system submitted for Task C of the SemEval2020 Task 4, which is to generate a reason explaining why a given false statement is non-sensical. However, we found in the early experiments that simple adaptations such as fine-tuning GPT2 often yield dull and non-informative generations (eg simple negations). In order to generate more meaningful explanations, we propose UNION, a unified end-to-end framework, to utilize several existing commonsense datasets so that it allows a model to learn more dynamics under the scope of commonsense reasoning. In order to perform model selection efficiently, accurately, and promptly, we also propose a couple of auxiliary automatic evaluation metrics so that we can extensively compare the models from different perspectives. Our submitted system not only results in a good performance in the proposed metrics but also outperforms its competitors with the highest achieved score of 2.10 for human evaluation while remaining a BLEU score of 15.7. Our code is made publicly available.},
  journal={SemEval},
  year={2020},
  publisher=aps,
  pdf={https://aclanthology.org/2020.semeval-1.45/},
  selected={false},
  code={https://github.com/anandhperumal/ANA-at-SemEval-2020-Task-4-UNION},
}

@article{u2net,
  abbr={PR},
  title={{U$^2$-Net}: Going Deeper with Nested U-Structure for Salient Object Detection},
  author={Qin, Xuebin and Zhang, Zichen and Huang, Chenyang and Dehghan, Masood and Zaiane, Osmar R and Jagersand, Martin},
  abstract={In this paper, we design a simple yet powerful deep network architecture, U2-Net, for salient object detection (SOD). The architecture of our U2-Net is a two-level nested U-structure. The design has the following advantages: (1) it is able to capture more contextual information from different scales thanks to the mixture of receptive fields of different sizes in our proposed ReSidual U-blocks (RSU), (2) it increases the depth of the whole architecture without significantly increasing the computational cost because of the pooling operations used in these RSU blocks. This architecture enables us to train a deep network from scratch without using backbones from image classification tasks. We instantiate two models of the proposed architecture, U2-Net (176.3 MB, 30 FPS on GTX 1080Ti GPU) and U2-Net† (4.7 MB, 40 FPS), to facilitate the usage in different environments. Both models achieve competitive performance on six SOD datasets.},
  journal={Pattern Recognition},
  year={2020},
  publisher=aps,
  url={https://aclanthology.org/2021.spnlp-1.7},
  pdf={https://aclanthology.org/2021.spnlp-1.7.pdf},
  selected={true},
  code={https://github.com/NathanUA/U-2-Net}
}

@article{basenet,
  abbr={CVPR},
  title={Basnet: Boundary-Aware Salient Object Detection},
  author={Qin, Xuebin and Zhang, Zichen and Huang, Chenyang and Gao, Chao and Dehghan, Masood and Jagersand, Martin},
  abstract={Deep Convolutional Neural Networks have been adopted for salient object detection and achieved the state-of-the-art performance. Most of the previous works however focus on region accuracy but not on the boundary quality. In this paper, we propose a predict-refine architecture, BASNet, and a new hybrid loss for Boundary-Aware Salient object detection. Specifically, the architecture is composed of a densely supervised Encoder-Decoder network and a residual refinement module, which are respectively in charge of saliency prediction and saliency map refinement. The hybrid loss guides the network to learn the transformation between the input image and the ground truth in a three-level hierarchy -- pixel-, patch- and map- level -- by fusing Binary Cross Entropy (BCE), Structural SIMilarity (SSIM) and Intersection-over-Union (IoU) losses. Equipped with the hybrid loss, the proposed predict-refine architecture is able to effectively segment the salient object regions and accurately predict the fine structures with clear boundaries. Experimental results on six public datasets show that our method outperforms the state-of-the-art methods both in terms of regional and boundary evaluation measures. Our method runs at over 25 fps on a single GPU. },
  journal={CVPR},
  year={2019},
  publisher=aps,
  url={https://openaccess.thecvf.com/content_CVPR_2019/html/Qin_BASNet_Boundary-Aware_Salient_Object_Detection_CVPR_2019_paper.html},
  pdf={https://openaccess.thecvf.com/content_CVPR_2019/papers/Qin_BASNet_Boundary-Aware_Salient_Object_Detection_CVPR_2019_paper.pdf},
  selected={true},
  code={https://github.com/xuebinqin/BASNet},
}

@article{semeval2019,
  abbr={SemEval},
  title={ANA at SemEval-2019 Task 3: Contextual Emotion Detection in Conversations Through Hierarchical LSTMs and BERT},
  author={Huang, Chenyang and Trabelsi, Amine and Za{\"\i}ane, Osmar R},
  abstract={This paper describes the system submitted by ANA Team for the SemEval-2019 Task 3: EmoContext. We propose a novel Hierarchical LSTMs for Contextual Emotion Detection (HRLCE) model. It classifies the emotion of an utterance given its conversational context. The results show that, in this task, our HRCLE outperforms the most recent state-of-the-art text classification framework: BERT. We combine the results generated by BERT and HRCLE to achieve an overall score of 0.7709 which ranked 5th on the final leader board of the competition among 165 Teams.},
  year={2019},
  publisher=aps,
  html={https://era.library.ualberta.ca/items/7f192eb3-04a5-458d-a71e-cb7d67ef85b5},
  selected={false},
  code={https://github.com/chenyangh/SemEval2019Task3},
  journal={SemEval},
}

@article{mscthesis,
  abbr={Thesis},
  title={Towards Emotion Intelligence in Neural Dialogue Systems},
  author={Chenyang Huang},
  abstract={Dialogue systems, also known as Conversational Agent (CA), are designed to mimic coherent conversations with humans. Most conversational agents are specialized for a specific domain such as travel booking and are typically finite state-based or template-based. Open domain dialogue systems have seen a growing interest in recent years thanks to neural dialogue generation systems, based on deep learning models.
These systems basically learn to predict the words and the sentence to respond based on the previous utterances. However, while such a system can generate grammatically correct and human-like answers, the responses are often generic and non-committal instead of being specific and emotionally intelligent. In this work, the objective is to tackle two main problems that are essential towards building emotionally intelligent chatbots:“How to detect the emotions expressed by the human accurately?” and “How can a chatbot express an emotion?”},
  year={2019},
  publisher=aps,
  html={https://era.library.ualberta.ca/items/7f192eb3-04a5-458d-a71e-cb7d67ef85b5},
  selected={false},
  code={https://github.com/chenyangh/DialogueGenerationWithEmotion},
  journal={University of Alberta},
}

@article{automatic,
  abbr={NAACL},
  title={Automatic Dialogue Generation with Expressed Emotions},
  author={Huang, Chenyang and Zaiane, Osmar R and Trabelsi, Amine and Dziri, Nouha},
  abstract={Dialogue systems, also known as Conversational Agent (CA), are designed to mimic coherent conversations with humans. Most conversational agents are specialized for a specific domain such as travel booking and are typically finite state-based or template-based. Open domain dialogue systems have seen a growing interest in recent years thanks to neural dialogue generation systems, based on deep learning models.
These systems basically learn to predict the words and the sentence to respond based on the previous utterances. However, while such a system can generate grammatically correct and human-like answers, the responses are often generic and non-committal instead of being specific and emotionally intelligent. In this work, the objective is to tackle two main problems that are essential towards building emotionally intelligent chatbots:“How to detect the emotions expressed by the human accurately?” and “How can a chatbot express an emotion?”},
  year={2018},
  publisher=aps,
  html={https://era.library.ualberta.ca/items/7f192eb3-04a5-458d-a71e-cb7d67ef85b5},
  selected={true},
  code={https://github.com/chenyangh/DialogueGenerationWithEmotion},
  journal={NAACL},
}

